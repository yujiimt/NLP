{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scale.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLxyzjmFZMas07n6I/dhP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yujiimt/NLP/blob/master/book/scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybuk7ja8n0RR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3a94be3-1e6c-400f-929b-ef202a3d4bb8"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "data = [[-1,2],[-0.5,6],[0,10],[1,18]]\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit_transform(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  ],\n",
              "       [0.25, 0.25],\n",
              "       [0.5 , 0.5 ],\n",
              "       [1.  , 1.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjHLsTxNolSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f7cd2d91-6ca2-4ad6-908f-e997b7e8f57d"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = [[0, 10],[0, 15], [1, 20], [1, 25]]\n",
        "scaler = StandardScaler()\n",
        "scaler.fit_transform(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        , -1.34164079],\n",
              "       [-1.        , -0.4472136 ],\n",
              "       [ 1.        ,  0.4472136 ],\n",
              "       [ 1.        ,  1.34164079]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDZ7U5KcqRPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "49080b73-8a55-480c-8fc2-a98d0e46bec1"
      },
      "source": [
        "!wget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz -P data/\n",
        "!gunzip -d data/amazon_reviews_multilingual_JP_v1_00.tsv.gz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-30 02:46:40--  https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.76.110\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.76.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94688992 (90M) [application/x-gzip]\n",
            "Saving to: ‘data/amazon_reviews_multilingual_JP_v1_00.tsv.gz’\n",
            "\n",
            "\r          amazon_re   0%[                    ]       0  --.-KB/s               \r         amazon_rev  17%[==>                 ]  16.13M  80.2MB/s               \r        amazon_revi  37%[======>             ]  34.09M  83.2MB/s               \r       amazon_revie  57%[==========>         ]  51.92M  85.2MB/s               \r      amazon_review  82%[===============>    ]  74.92M  92.5MB/s               \r     amazon_reviews  93%[=================>  ]  84.69M  83.9MB/s               \ramazon_reviews_mult 100%[===================>]  90.30M  81.2MB/s    in 1.1s    \n",
            "\n",
            "2020-04-30 02:46:41 (81.2 MB/s) - ‘data/amazon_reviews_multilingual_JP_v1_00.tsv.gz’ saved [94688992/94688992]\n",
            "\n",
            "gzip: data/amazon_reviews_multilingual_JP_v1_00.tsv already exists; do you wish to overwrite (y or n)? ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dTBMJ2M-NVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "803d6982-4dc2-4b86-c14a-628cad40df71"
      },
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "!pip install janome\n",
        "from bs4 import BeautifulSoup\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "t = Tokenizer(wakati = True)\n",
        "\n",
        "def filter_by_ascii_rate(text, threshold = 0.9):\n",
        "  ascii_letters = set(string.printable)\n",
        "  rate = sum(c in ascii_letters for c in text) / len(text)\n",
        "  return rate <= threshold\n",
        "\n",
        "\n",
        "def load_dataset(filename, n=5000, state = 6):\n",
        "  df = pd.read_csv(filename, sep = '\\t')\n",
        "\n",
        "  # マルチクラスに変更\n",
        "  mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n",
        "  df = df[df.star_rating != 3]\n",
        "  df.star_rating = df.star_rating.map(mapping)\n",
        "\n",
        "  #日本語処理\n",
        "  is_jp = df.review_body.apply(filter_by_ascii_rate)\n",
        "  df = df[is_jp]\n",
        "\n",
        "  # sampling\n",
        "  df = df.sample(frac = 1, random_state = state)\n",
        "  grouped = df.groupby('star_rating')\n",
        "  df = grouped.head(n=n)\n",
        "  return df.review_body.values, df.star_rating.values\n",
        "def clean_html(html, strip = False):\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  text = soup.get_text(strip =  strip)\n",
        "  return text\n",
        "  \n",
        "def tokenize(text):\n",
        "  return t.tokenize(text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/f0/bd7f90806132d7d9d642d418bdc3e870cfdff5947254ea3cab27480983a7/Janome-0.3.10-py2.py3-none-any.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 1.2MB/s \n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.3.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9N2pboms-ja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fc343a91-93d6-4a70-9f4c-d9248f8d009a"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "  print('Loading ..... ')\n",
        "  x, y = load_dataset('/content/data/amazon_reviews_multilingual_JP_v1_00.tsv', n = 5000)\n",
        "  x = [clean_html(text, strip = True) for text in x]\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)\n",
        "\n",
        "\n",
        "  print('Vectorizing....')\n",
        "  vectorizer = CountVectorizer(tokenizer = tokenize)\n",
        "  x_train = vectorizer.fit_transform(x_train)\n",
        "  x_test = vectorizer.transform(x_test)\n",
        "  print(x_train.shape)\n",
        "  print(x_test.shape)\n",
        "\n",
        "  print('selecting feature ....')\n",
        "  selector = SelectKBest(k = 7000, score_func = mutual_info_classif)\n",
        "  selector.fit(x_train, y_train)\n",
        "  x_train_new = selector.transform(x_train)\n",
        "  x_test_new = selector.transform(x_test)\n",
        "  print(x_train_new.shape)\n",
        "  print(x_test_new.shape)\n",
        "\n",
        "  print(\"Evaluting .... \")\n",
        "  clf = LogisticRegression(solver = 'liblinear')\n",
        "  clf.fit(x_train_new, y_train)\n",
        "  y_pred = clf.predict(x_test_new)\n",
        "  score = accuracy_score(y_test, y_pred)\n",
        "  print('{:.4f}'.format(score))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading ..... \n",
            "Vectorizing....\n",
            "(8000, 40980)\n",
            "(2000, 40980)\n",
            "selecting feature ....\n",
            "(8000, 7000)\n",
            "(2000, 7000)\n",
            "Evaluting .... \n",
            "0.8370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4RlapTz4qCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
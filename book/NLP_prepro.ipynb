{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_prepro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMuyvfU/1R/A7jtmf8TsV0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yujiimt/NLP/blob/master/book/NLP_prepro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rtfYA6ENuwL",
        "colab_type": "code",
        "outputId": "c165e9bf-c244-4998-9634-53059783c496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz -P data/\n",
        "!gunzip -d data/amazon_reviews_multilingual_JP_v1_00.tsv.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-28 05:58:58--  https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.85.77\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.85.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94688992 (90M) [application/x-gzip]\n",
            "Saving to: ‘data/amazon_reviews_multilingual_JP_v1_00.tsv.gz.1’\n",
            "\n",
            "\r          amazon_re   0%[                    ]       0  --.-KB/s               \r         amazon_rev  14%[=>                  ]  12.72M  58.7MB/s               \r        amazon_revi  28%[====>               ]  25.81M  62.0MB/s               \r       amazon_revie  40%[=======>            ]  36.94M  59.9MB/s               \r      amazon_review  70%[=============>      ]  63.99M  71.4MB/s               \r     amazon_reviews  92%[=================>  ]  83.61M  76.3MB/s               \ramazon_reviews_mult 100%[===================>]  90.30M  79.6MB/s    in 1.1s    \n",
            "\n",
            "2020-04-28 05:58:59 (79.6 MB/s) - ‘data/amazon_reviews_multilingual_JP_v1_00.tsv.gz.1’ saved [94688992/94688992]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf1l9LZOq0Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path, urllib.request as request"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMb_xLOkrhbl",
        "colab_type": "code",
        "outputId": "abcd73b5-e4a1-4c10-a6d2-7cca81463b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\"\n",
        "localfile = \"amazon_reviews_multilingual_JP_v1_00.tsv\"\n",
        "\n",
        "if not os.path.exists(localfile):\n",
        "  print(\"ファイルをダウンロード\")\n",
        "  request.urlretrieve(url, localfile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ファイルをダウンロード\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbuhu-BpsxJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "def filter_by_ascii_rate(text, threshold = 0.9):\n",
        "  ascii_letters = set(string.printable)\n",
        "  rate = sum(c in ascii_letters for c in text) / len(text)\n",
        "  return rate <= threshold\n",
        "\n",
        "def load_dataset(filename, n=5000, state=6):\n",
        "  df = pd.read_csv(filename, sep = \"\\t\")\n",
        "\n",
        "  # extracts Japanese texts\n",
        "\n",
        "  is_jp = df.review_body.apply(filter_by_ascii_rate)\n",
        "  df = df[is_jp]\n",
        "\n",
        "  # sampling\n",
        "  df = df.sample(frac=1, random_state = state)\n",
        "  grouped = df.groupby(\"star_rating\")\n",
        "  df = grouped.head(n=n)\n",
        "  return df.review_body.values, df.star_rating.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAaUWReDs3kQ",
        "colab_type": "code",
        "outputId": "07e853b2-0035-40bd-dd92-0df35b66c596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install janome\n",
        "\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from janome.tokenizer import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: janome in /usr/local/lib/python3.6/dist-packages (0.3.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yMdStPNtPnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer()\n",
        "\n",
        "def clean_html(html, strip = False):\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  text = soup.get_text(strip=strip)\n",
        "  return text\n",
        "\n",
        "def tokenize(text):\n",
        "  return t.tokenize(text, wakati = True)\n",
        "\n",
        "def tokenize_base_form(text):\n",
        "  tokens = [token.base_form for token in t.tokenize(text)]\n",
        "  return tokens\n",
        "\n",
        "def normalize_number(text, reduce = False):\n",
        "  if reduce:\n",
        "    normalized_text = re.sub(r'\\d+', '0', text)\n",
        "  else:\n",
        "    normalized_text = re.sub(r'\\d', '0', text)\n",
        "  return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsg9_jgpCGhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_and_eval(x_train, y_train, x_test, y_test, lowercase = False, tokenize = None, preprocessor = None):\n",
        "  vectorizer = CountVectorizer(lowercase = lowercase,\n",
        "                               tokenizer = tokenize,\n",
        "                               preprocessor = preprocessor)\n",
        "  x_train_vec = vectorizer.fit_transform(x_train)\n",
        "  x_test_vec = vectorizer.transform(x_test)\n",
        "  clf = LogisticRegression(solver = 'liblinear')\n",
        "  clf.fit(x_train_vec, y_train)\n",
        "  y_pred = clf.predict(x_test_vec)\n",
        "  score = accuracy_score(y_test, y_pred)\n",
        "  print('{:.4f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBlHdnKwHMMv",
        "colab_type": "code",
        "outputId": "a9a00701-3570-4744-de0f-ac72ef6ffc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def main():\n",
        "  x,y = load_dataset('/content/data/amazon_reviews_multilingual_JP_v1_00.tsv', n = 1000)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)\n",
        "  \n",
        "  print('Tokenization only')\n",
        "  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize)\n",
        "  \n",
        "  print('Clean html')\n",
        "  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize, preprocessor = clean_html)\n",
        "\n",
        "  print('Normalize number')\n",
        "  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize, preprocessor = normalize_number)\n",
        "\n",
        "  print(\"Base form\")\n",
        "  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize_base_form)\n",
        "\n",
        "  print(\"Lower text\")\n",
        "  train_and_eval(x_train, y_train, x_test, y_test, tokenize = tokenize, lowercase = True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenization only\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.4020\n",
            "Clean html\n",
            "0.4090\n",
            "Normalize number\n",
            "0.3940\n",
            "Base form\n",
            "0.3930\n",
            "Lower text\n",
            "0.3980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFTbIpUeMZIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}